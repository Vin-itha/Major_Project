#!/usr/bin/env python
# coding: utf-8

# <a href="https://colab.research.google.com/github/Vin-itha/Major_Project/blob/main/trainmodel.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

# In[ ]:
# import os
# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 0=all, 1=info, 2=warning, 3=error


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers # type: ignore
from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input # type: ignore
# AFTER (Correct)
#from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B0, preprocess_input # type: ignore

DATASET_PATH = r"D:/Project_Leaf_train/new_dataset"
IMG_SIZE = (224, 224)
BATCH_SIZE = 32

train_ds = tf.keras.utils.image_dataset_from_directory(
    DATASET_PATH + "/train",
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    seed=123,
    color_mode="rgb"   
)
val_ds = tf.keras.utils.image_dataset_from_directory(
    DATASET_PATH + "/validation",
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    seed=123,
    color_mode="rgb"
)
test_ds = tf.keras.utils.image_dataset_from_directory(
    DATASET_PATH + "/test",
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    seed=123,
    color_mode="rgb"
)

class_names = train_ds.class_names
print("Classes:", class_names)


data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.2),
    layers.RandomZoom(0.2),
    layers.RandomContrast(0.2),
    layers.RandomTranslation(0.1, 0.1),
])

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.map(lambda x, y: (preprocess_input(x), y)).prefetch(AUTOTUNE)
val_ds   = val_ds.map(lambda x, y: (preprocess_input(x), y)).prefetch(AUTOTUNE)
test_ds  = test_ds.map(lambda x, y: (preprocess_input(x), y)).prefetch(AUTOTUNE)


# Explicit RGB input
inputs = keras.Input(shape=(224, 224, 3))

# Data augmentation first
x = data_augmentation(inputs)

# Base model (pretrained ImageNet weights)
base_model = keras.applications.EfficientNetV2B0(
    include_top=False,
    weights="imagenet",
    input_shape=(224,224,3)
)
base_model.trainable = True   

for layer in base_model.layers[:-30]:
    layer.trainable = False

x = base_model(x, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3)(x)
x = layers.Dense(128, activation="relu")(x)
x = layers.Dropout(0.2)(x)
outputs = layers.Dense(len(class_names), activation="softmax")(x)

model = keras.Model(inputs, outputs)


model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=1e-4),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

model.summary()


early_stop = keras.callbacks.EarlyStopping(
    monitor="val_loss",
    patience=5,
    restore_best_weights=True
)


EPOCHS = 20  
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    callbacks=[early_stop]
)


test_loss, test_acc = model.evaluate(test_ds)
print("\nâœ… EfficientNetB0 Test Accuracy:", test_acc)


model.save("Efficientnet_Leaf_Model1.keras")


# In[3]:


import tensorflow as tf
model = tf.keras.models.load_model("Efficientnet_Leaf_Model1.keras")

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with open("Leaf_Model1.tflite", "wb") as f:
    f.write(tflite_model)


# In[4]:


import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt

y_true, y_pred = [], []
for images, labels in test_ds:
    preds = model.predict(images)
    y_true.extend(labels.numpy())
    y_pred.extend(np.argmax(preds, axis=1))

cm = confusion_matrix(y_true, y_pred)
print(classification_report(y_true, y_pred, target_names=class_names))

plt.imshow(cm, cmap="Blues")
plt.title("Confusion Matrix")
plt.colorbar()
plt.xticks(range(len(class_names)), class_names, rotation=45)
plt.yticks(range(len(class_names)), class_names)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()


# In[ ]:


import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing import image # type: ignore
import os
import csv

model = tf.keras.models.load_model("Efficientnet_Leaf_Model1.keras")

class_names = ["Bael", "Betel", "Crown Flower","Other"]

def predict_image(img_path):
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = tf.keras.applications.efficientnet_v2.preprocess_input(img_array)

    preds = model.predict(img_array, verbose=0)
    predicted_class = class_names[np.argmax(preds)]
    confidence = float(np.max(preds))

    return predicted_class, confidence

# === Run predictions on entire test dataset ===
base_path = r"D:/Project_Leaf_train/new_dataset/test"
output_csv = r"D:/Project_Leaf_train/Leaf_Predictions1.csv"

with open(output_csv, mode="w", newline="") as f:
    writer = csv.writer(f)
    writer.writerow(["Filename", "True_Class", "Predicted_Class", "Confidence"])

    for true_class in class_names:
        folder = os.path.join(base_path, true_class)
        for file in os.listdir(folder):
            if file.lower().endswith((".jpg", ".jpeg", ".png")):
                img_path = os.path.join(folder, file)
                predicted_class, confidence = predict_image(img_path)
                writer.writerow([file, true_class, predicted_class, confidence])

print(f"âœ… Predictions saved to {output_csv}")


# In[ ]:


import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix

def smart_classification_report_and_visuals(csv_path, true_col="True_Class", pred_col="Predicted_Class"):
    df = pd.read_csv(csv_path)
    y_true = df[true_col]
    y_pred = df[pred_col]

    # Classification report
    report = classification_report(y_true, y_pred, output_dict=True)
    report_df = pd.DataFrame(report).transpose()

    # --- 1. Text Summary ---
    print("ðŸ“Š Classification Report\n")
    for cls in report_df.index[:-3]: 
        precision = report_df.loc[cls, "precision"]
        recall = report_df.loc[cls, "recall"]

        if recall < 0.9 and precision >= 0.9:
            note = f"â†’ Model sometimes misses {cls} ({(1-recall)*100:.0f}% false negatives)."
        elif precision < 0.9 and recall >= 0.9:
            note = f"â†’ Almost every {cls} is detected, but other classes are misclassified as {cls}."
        elif precision >= 0.95 and recall >= 0.95:
            note = "â†’ Nearly perfect."
        else:
            note = f"â†’ Balanced but could improve."

        print(f"{cls} â†’ Precision {precision:.2f}, Recall {recall:.2f} {note}")

    print(f"\nâœ… Overall Test Accuracy = {report['accuracy']*100:.2f}% ðŸŽ¯")


    # Bar chart: Precision vs Recall
    classes = report_df.index[:-3]
    precision = report_df.loc[classes, "precision"]
    recall = report_df.loc[classes, "recall"]

    x = range(len(classes))
    plt.figure(figsize=(8,5))
    plt.bar(x, precision, width=0.4, label="Precision", align="center")
    plt.bar([i+0.4 for i in x], recall, width=0.4, label="Recall", align="center")
    plt.xticks([i+0.2 for i in x], classes)
    plt.ylim(0,1)
    plt.ylabel("Score")
    plt.title("Precision vs Recall per Class")
    plt.legend()
    plt.show()

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred, labels=classes)
    fig, ax = plt.subplots(figsize=(6,5))
    im = ax.imshow(cm, cmap="Greens")

    for i in range(len(classes)):
        for j in range(len(classes)):
            ax.text(j, i, cm[i, j], ha="center", va="center", color="black")

    ax.set_xticks(range(len(classes)))
    ax.set_yticks(range(len(classes)))
    ax.set_xticklabels(classes)
    ax.set_yticklabels(classes)
    ax.set_xlabel("Predicted")
    ax.set_ylabel("True")
    plt.title("Confusion Matrix")
    plt.colorbar(im)
    plt.show()

csv_path = r"D:/Project_Leaf_train/Leaf_Predictions1.csv"
smart_classification_report_and_visuals(csv_path)






